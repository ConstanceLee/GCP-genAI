{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Building a Weather Agent with AutoGen and Gemini\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/orchestration/autogen_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Forchestration%2Fautogen_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/orchestration/autogen_gemini.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/orchestration/autogen_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Karl Weinmeister](https://github.com/kweinmeister/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to build a weather agent using [Autogen](https://microsoft.github.io/autogen/) with the [Gemini Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) model on Vertex AI model. The agent can understand free-form location queries, retrieve location coordinates using the [Nominatim API](https://nominatim.org/release-docs/latest/api/Overview/), and fetch weather forecasts using the [Open-Meteo API](https://open-meteo.com/en/docs). This example showcases Autogen's ability to integrate external APIs and tools within a conversational AI framework.\n",
        "\n",
        "By the end of this notebook, you will learn how to:\n",
        "\n",
        "* Define custom functions using Autogen's function registration decorators.\n",
        "* Integrate external APIs (Nominatim and Open-Meteo) within your agent's functions.\n",
        "* Create and manage conversations between a user proxy agent and a specialized assistant agent.\n",
        "* Leverage Gemini for natural language understanding and response generation.\n",
        "\n",
        "## Steps performed in this notebook:\n",
        "\n",
        "* Define an [AssistantAgent](https://microsoft.github.io/autogen/docs/reference/agentchat/assistant_agent/) for weather information and a [UserProxyAgent](https://microsoft.github.io/autogen/docs/reference/agentchat/user_proxy_agent/) to simulate user interaction.\n",
        "* Register custom Python functions (`search_location` and `get_weather_forecast`) with the AssistantAgent, making them callable by the language model.\n",
        "* Integrate with the Nominatim API to geocode location queries and the Open-Meteo API to fetch weather forecasts.\n",
        "* Initiate a chat between the user proxy and the weather agent, providing a sample query like \"What's the weather like in Paris?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user --quiet google-cloud-aiplatform pyautogen[gemini]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvKdaPDTznN",
        "outputId": "77242f56-79fe-4690-8b66-d7fa07f9c4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and configure Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\", isTemplate: true}\n",
        "if PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "# Pricing parameters for AutoGen using the OpenAI API.\n",
        "# The agent will work without these, but will log warnings.\n",
        "# For latest pricing, see:\n",
        "# https://cloud.google.com/vertex-ai/generative-ai/pricing\n",
        "INPUT_PRICE_1K_CHARS = 0.00001875\n",
        "OUTPUT_PRICE_1K_CHARS = 0.000075\n",
        "OUTPUT_PRICE_1K_TOKENS = OUTPUT_PRICE_1K_CHARS * 4  # Estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVfOrSWjDaQM"
      },
      "source": [
        "## LLM Configuration\n",
        "\n",
        "Next, we will define the AutoGen [LLM configuration](https://microsoft.github.io/autogen/docs/topics/llm_configuration/) for AutoGen.\n",
        "\n",
        "As [tool use](https://microsoft.github.io/autogen/docs/tutorial/tool-use) in AutoGen is currently limited to the OpenAI API, we'll use the OpenAI [interface in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/call-vertex-using-openai-library).\n",
        "\n",
        "You can find more details on configuring AutoGen for Vertex AI Gemini API [here](https://microsoft.github.io/autogen/docs/topics/non-openai-models/cloud-gemini_vertexai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttZIXTjR4d6b"
      },
      "outputs": [],
      "source": [
        "import google.auth\n",
        "\n",
        "scopes = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "creds, _ = google.auth.default(scopes)\n",
        "auth_req = google.auth.transport.requests.Request()\n",
        "creds.refresh(auth_req)\n",
        "\n",
        "config_list = [\n",
        "    {\n",
        "        \"model\": \"google/gemini-1.5-flash-001\",\n",
        "        \"api_type\": \"openai\",\n",
        "        \"base_url\": f\"https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\",\n",
        "        \"api_key\": creds.token,\n",
        "        \"price\": [INPUT_PRICE_1K_CHARS, OUTPUT_PRICE_1K_TOKENS]\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5l1bslxJIsn"
      },
      "source": [
        "## Agent development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "from autogen import AssistantAgent, UserProxyAgent, Cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Define agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-yf-oOlGCBf"
      },
      "source": [
        "An [AssistantAgent](https://microsoft.github.io/autogen/docs/reference/agentchat/assistant_agent/) in AutoGen is a specialized agent designed to perform specific tasks or provide information within a conversational AI framework. It leverages a large language model to generate responses and interact with other agents.\n",
        "\n",
        "In this scenario, our `weather_agent` will be responsible for understanding user queries about the weather, retrieving relevant information from external APIs (like location coordinates and weather forecasts), and providing formatting responses to the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykoCz0_N6okC"
      },
      "outputs": [],
      "source": [
        "weather_agent = AssistantAgent(\n",
        "    name=\"WeatherAgent\",\n",
        "    description=\"\"\"A weather assistant that summarizes and provides helpful\n",
        "    details, customized for the user's query.\"\"\",\n",
        "    llm_config={\n",
        "        \"config_list\": config_list,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0l584q7GmZ3"
      },
      "source": [
        "A [UserProxyAgent](https://microsoft.github.io/autogen/docs/reference/agentchat/user_proxy_agent/) is an agent that acts as a proxy for a human user within a conversational AI system.  It can receive user input, either directly from a human user or from a predefined script, and then forward it to the other agents in the conversation.\n",
        "\n",
        "In this scenario, the UserProxyAgent will be responsible for simulating a user who is interested in learning about the weather. It will receive user queries, such as \"What's the weather like in Paris?\", and forward them to the `weather_agent`. The `UserProxyAgent` will also receive the response from the `weather_agent` and display it to the user.\n",
        "\n",
        "This allows us to test and explore the capabilities of the `weather_agent` without requiring a human user to interact with the system directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5dU67wqFmXZ"
      },
      "outputs": [],
      "source": [
        "user_proxy = UserProxyAgent(\n",
        "    name=\"UserProxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"use_docker\": False},\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\")\n",
        "    and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWxBh5NNHEzK"
      },
      "source": [
        "## Define tools\n",
        "\n",
        "There will be two tools we use in this scenario:\n",
        "* `search_location` helps us pinpoint coordinates based on the user's query\n",
        "* `get_weather_forecast` accepts the coordinates and then retrieves the weather\n",
        "\n",
        "We will [register each tool](https://microsoft.github.io/autogen/docs/tutorial/tool-use/#registering-tools) using a decorator, so each agent can use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg1AwuVL6uPF"
      },
      "outputs": [],
      "source": [
        "@user_proxy.register_for_execution()\n",
        "@weather_agent.register_for_llm(description=\"Performs a free-form location search using the Nominatim API.\")\n",
        "def search_location(query: str) -> tuple[float, float]:\n",
        "    \"\"\"Performs a free-form location search using the Nominatim API.\"\"\"\n",
        "    base_url = \"https://nominatim.openstreetmap.org/search\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"format\": \"jsonv2\",\n",
        "        \"addressdetails\": 1,\n",
        "        \"email\": \"your_email@example.com\",  # Replace with your email\n",
        "    }\n",
        "    headers = {\n",
        "        \"User-Agent\": f\"MyWeatherApp/1.0 ({params['email']})\",\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        search_results = response.json()\n",
        "        lat = float(search_results[0][\"lat\"])\n",
        "        lon = float(search_results[0][\"lon\"])\n",
        "        return lat, lon\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during Nominatim API request: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv1hYDB76vG7"
      },
      "outputs": [],
      "source": [
        "@user_proxy.register_for_execution()\n",
        "@weather_agent.register_for_llm(description=\"Retrieves the weather forecast for a given latitude and longitude.\")\n",
        "def get_weather_forecast(latitude: float, longitude: float) -> dict:\n",
        "    \"\"\"Retrieves the weather forecast using the Open Meteo API.\"\"\"\n",
        "    base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "    params = {\n",
        "        \"latitude\": latitude,\n",
        "        \"longitude\": longitude,\n",
        "        \"daily\": \"temperature_2m_max,temperature_2m_min,precipitation_sum,windspeed_10m_max\",\n",
        "        \"timezone\": \"auto\",\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        weather_forecast = response.json()\n",
        "        print(weather_forecast)\n",
        "        return weather_forecast\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during Open Meteo API request: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7zx1nGBDCEX"
      },
      "source": [
        "## Initiate conversation\n",
        "\n",
        "We are ready to test our agent! We will [initiate the chat](https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent/#initiate_chat), where you can see each step. The agents will perform tasks and communicate with each other.\n",
        "\n",
        "[Caching](https://microsoft.github.io/autogen/docs/topics/llm-caching]) is enabled to reduce cost in our testing scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTgPXBze6znD",
        "outputId": "dc5b9020-11cf-445c-fed4-7210983b48d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UserProxy (to WeatherAgent):\n",
            "\n",
            "What's the weather like in Paris?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-14 14:59:31] {349} WARNING - Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:autogen.oai.client:Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WeatherAgent (to UserProxy):\n",
            "\n",
            "***** Suggested tool call (search_location): search_location *****\n",
            "Arguments: \n",
            "{\"query\":\"Paris\"}\n",
            "******************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION search_location...\n",
            "UserProxy (to WeatherAgent):\n",
            "\n",
            "UserProxy (to WeatherAgent):\n",
            "\n",
            "***** Response from calling tool (search_location) *****\n",
            "[48.8534951, 2.3483915]\n",
            "********************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-14 14:59:33] {349} WARNING - Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:autogen.oai.client:Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WeatherAgent (to UserProxy):\n",
            "\n",
            "***** Suggested tool call (get_weather_forecast): get_weather_forecast *****\n",
            "Arguments: \n",
            "{\"latitude\":48.8534951,\"longitude\":2.3483915}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION get_weather_forecast...\n",
            "{'latitude': 48.86, 'longitude': 2.3399997, 'generationtime_ms': 0.10597705841064453, 'utc_offset_seconds': 7200, 'timezone': 'Europe/Paris', 'timezone_abbreviation': 'CEST', 'elevation': 43.0, 'daily_units': {'time': 'iso8601', 'temperature_2m_max': '°C', 'temperature_2m_min': '°C', 'precipitation_sum': 'mm', 'windspeed_10m_max': 'km/h'}, 'daily': {'time': ['2024-09-14', '2024-09-15', '2024-09-16', '2024-09-17', '2024-09-18', '2024-09-19', '2024-09-20'], 'temperature_2m_max': [17.6, 19.7, 20.5, 19.6, 22.2, 19.5, 20.4], 'temperature_2m_min': [7.3, 7.7, 11.8, 11.1, 12.8, 13.7, 13.4], 'precipitation_sum': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1], 'windspeed_10m_max': [10.0, 7.7, 11.6, 19.4, 18.0, 15.0, 7.0]}}\n",
            "UserProxy (to WeatherAgent):\n",
            "\n",
            "UserProxy (to WeatherAgent):\n",
            "\n",
            "***** Response from calling tool (get_weather_forecast) *****\n",
            "{\"latitude\": 48.86, \"longitude\": 2.3399997, \"generationtime_ms\": 0.10597705841064453, \"utc_offset_seconds\": 7200, \"timezone\": \"Europe/Paris\", \"timezone_abbreviation\": \"CEST\", \"elevation\": 43.0, \"daily_units\": {\"time\": \"iso8601\", \"temperature_2m_max\": \"°C\", \"temperature_2m_min\": \"°C\", \"precipitation_sum\": \"mm\", \"windspeed_10m_max\": \"km/h\"}, \"daily\": {\"time\": [\"2024-09-14\", \"2024-09-15\", \"2024-09-16\", \"2024-09-17\", \"2024-09-18\", \"2024-09-19\", \"2024-09-20\"], \"temperature_2m_max\": [17.6, 19.7, 20.5, 19.6, 22.2, 19.5, 20.4], \"temperature_2m_min\": [7.3, 7.7, 11.8, 11.1, 12.8, 13.7, 13.4], \"precipitation_sum\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1], \"windspeed_10m_max\": [10.0, 7.7, 11.6, 19.4, 18.0, 15.0, 7.0]}}\n",
            "*************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 09-14 14:59:34] {349} WARNING - Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:autogen.oai.client:Model google/gemini-1.5-flash-001 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WeatherAgent (to UserProxy):\n",
            "\n",
            "The weather in Paris for the next few days will be mostly dry with highs in the low 20s Celsius and lows in the mid teens. There's a chance of rain on September 20th.  \n",
            "TERMINATE\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with Cache.disk() as cache:\n",
        "\n",
        "  result = user_proxy.initiate_chat(\n",
        "      weather_agent,\n",
        "      message=\"What's the weather like in Paris?\",\n",
        "      cache=cache\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JMQy8e5Ix4X"
      },
      "source": [
        "Let's extract the summary from the `result`. Congratulations on finishing the tutorial! 🎉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nsv7eu9AnuP",
        "outputId": "a5aab191-fbaa-41db-929b-f3268ad2f3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The weather in Paris is expected to be mostly sunny with a high of 20.4 degrees Celsius and a low of 13.4 degrees Celsius on September 20th. There is a chance of precipitation on that day.  \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(result.summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
